{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of multilingual data on the model\n",
    "\n",
    "This notebook contains the code necessary for evaluating the performance of the model trained on only the Enlish dataset and the model trained on the Multilingual dataset. The performance difference between the models is statistically evaluated to determine whether there are significant differences in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "import numpy as np\n",
    "from subprocess import call\n",
    "import sys\n",
    "sys.path.insert(0, './src/')\n",
    "from src import util\n",
    "import IPython.display as ipd\n",
    "import json\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import random\n",
    "import csv\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## important methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_calc(y_true, y_pred):\n",
    "    mae_ = mae(y_true, y_pred)\n",
    "    stdev = np.std(abs(y_true.astype(np.float)-y_pred.astype(np.float)))\n",
    "    rel_mae = np.mean(abs(y_pred-y_true)/ (y_true+0.00001))\n",
    "    rel_err = (y_pred-y_true)/ (y_true+0.00001)\n",
    "    return mae_,stdev,rel_mae, rel_err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_dist(data):\n",
    "    plt.hist(data, density=True)\n",
    "    mu, sigma = stats.norm.fit(data)\n",
    "    x = np.linspace(mu - 3* sigma, mu + 3*sigma,100 )\n",
    "    plt.plot(x, stats.norm.pdf(x,mu,sigma))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttest(x,y):\n",
    "    t,p = stats.ttest_rel(x,y)\n",
    "    return np.abs(t),p/2 #one sided t-test.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/vol/tensusers3/camghane/ASR/predictions.json') as json_file:\n",
    "    data = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_english_y_true = data['y_true']\n",
    "baseline_english_y_pred = data['y_pred']\n",
    "\n",
    "cm_train = confusion_matrix(baseline_english_y_true, baseline_english_y_true, labels=range(11))\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(1,1, figsize=(5,5))\n",
    "\n",
    "\n",
    "\n",
    "# Plot confusion matrix for training data\n",
    "sns.heatmap(cm_train, annot=True, fmt='g', ax=ax, cmap=\"Blues\")\n",
    "\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix for Baseline Model on the English testset')\n",
    "\n",
    "b, t = plt.ylim() # discover the values for bottom and top\n",
    "b += 0.5 # Add 0.5 to the bottom\n",
    "t -= 0.5 # Subtract 0.5 from the top\n",
    "plt.ylim(b, t) # update the ylim(bottom, top) values\n",
    "plt.savefig(\"confusion_baseline.png\", bbox_inches='tight')\n",
    "plt.show() # ta-da!\n",
    "\n",
    "# Show the result\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_english_y_true = np.array(baseline_english_y_true)\n",
    "baseline_english_y_pred = np.array(baseline_english_y_pred)\n",
    "\n",
    "baseline_english_mae, baseline_english_stdev, baseline_english_relative_mae,baseline_english_rel_err = stats_calc(baseline_english_y_true, baseline_english_y_pred)\n",
    "\n",
    "print(\"MAE: {}\".format(baseline_english_mae))\n",
    "print(\"MAE St.Dev.: {}\".format(baseline_english_stdev))\n",
    "print(\"Relative MAE: {}\".format(baseline_english_relative_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilingual dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/vol/tensusers3/camghane/ASR/MLS/predictions_experiment1.json') as json_file:\n",
    "    data = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilingual_english_y_true = data['y_true']\n",
    "multilingual_english_y_pred = data['y_pred']\n",
    "\n",
    "cm_train = confusion_matrix(multilingual_english_y_true, multilingual_english_y_pred, labels=range(11))\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(1,1, figsize=(5,5))\n",
    "\n",
    "\n",
    "\n",
    "# Plot confusion matrix for training data\n",
    "sns.heatmap(cm_train, annot=True, fmt='g', ax=ax, cmap=\"Blues\")\n",
    "\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix for MultiLingual Model on the English testset')\n",
    "\n",
    "b, t = plt.ylim() # discover the values for bottom and top\n",
    "b += 0.5 # Add 0.5 to the bottom\n",
    "t -= 0.5 # Subtract 0.5 from the top\n",
    "plt.ylim(b, t) # update the ylim(bottom, top) values\n",
    "plt.savefig(\"confusion_multilingualmodel_english_dataset.png\", bbox_inches='tight')\n",
    "plt.show() # ta-da!\n",
    "\n",
    "# Show the result\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilingual_english_y_true = np.array(multilingual_english_y_true)\n",
    "multilingual_english_y_pred = np.array(multilingual_english_y_pred)\n",
    "\n",
    "multilingual_english_mae, multilingual_english_stdev, multilingual_english_relative_mae,multilingual_english_rel_error = stats_calc(multilingual_english_y_true, multilingual_english_y_pred)\n",
    "\n",
    "print(\"MAE: {}\".format(multilingual_english_mae))\n",
    "print(\"MAE St.Dev.: {}\".format(multilingual_english_stdev))\n",
    "print(\"Relative MAE: {}\".format(multilingual_english_relative_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Distribution of relative errors for the Baseline model on the English Testset\")\n",
    "plot_data_dist(baseline_english_rel_err)\n",
    "print(\"Distribution of relative errors for the Multilingual model on the English Testset\")\n",
    "\n",
    "plot_data_dist(multilingual_english_rel_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tval,pval = ttest(baseline_english_rel_err, multilingual_english_rel_error)\n",
    "print(f\"The p val : {pval} and t val {tval} for one sided (paired) t-test on the English dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilingual testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/vol/tensusers3/camghane/ASR/MLS/baseline_predictions_experiment1_multilingualdataset.json') as json_file:\n",
    "    data = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_multilingual_y_true = data['y_true']\n",
    "baseline_multilingual_y_pred = data['y_pred']\n",
    "\n",
    "cm_train = confusion_matrix(baseline_multilingual_y_true, baseline_multilingual_y_pred, labels=range(11))\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(1,1, figsize=(5,5))\n",
    "\n",
    "\n",
    "\n",
    "# Plot confusion matrix for training data\n",
    "sns.heatmap(cm_train, annot=True, fmt='g', ax=ax, cmap=\"Blues\")\n",
    "\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix for Baseline Model on the Multilingual testset')\n",
    "\n",
    "b, t = plt.ylim() # discover the values for bottom and top\n",
    "b += 0.5 # Add 0.5 to the bottom\n",
    "t -= 0.5 # Subtract 0.5 from the top\n",
    "plt.ylim(b, t) # update the ylim(bottom, top) values\n",
    "plt.savefig(\"confusion_baselinemodel_multilingual_dataset.png\", bbox_inches='tight')\n",
    "plt.show() # ta-da!\n",
    "\n",
    "# Show the result\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_multilingual_y_true = np.array(baseline_multilingual_y_true)\n",
    "baseline_multilingual_y_pred = np.array(baseline_multilingual_y_pred)\n",
    "\n",
    "baseline_multilingual_mae, baseline_multilingual_stdev, baseline_multilingual_relative_mae,baseline_multilingual_rel_error = stats_calc(baseline_multilingual_y_true, baseline_multilingual_y_pred)\n",
    "\n",
    "print(\"MAE: {}\".format(baseline_multilingual_mae))\n",
    "print(\"MAE St.Dev.: {}\".format(baseline_multilingual_stdev))\n",
    "print(\"Relative MAE: {}\".format(baseline_multilingual_relative_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multilingual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/vol/tensusers3/camghane/ASR/MLS/multilingual_predictions_experiment1_multilingualdataset.json') as json_file:\n",
    "    data = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilingual_multilingual_y_true = data['y_true']\n",
    "multilingual_multilingual_y_pred = data['y_pred']\n",
    "\n",
    "cm_train = confusion_matrix(multilingual_multilingual_y_true, multilingual_multilingual_y_pred, labels=range(11))\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(1,1, figsize=(5,5))\n",
    "\n",
    "\n",
    "\n",
    "# Plot confusion matrix for training data\n",
    "sns.heatmap(cm_train, annot=True, fmt='g', ax=ax, cmap=\"Blues\")\n",
    "\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix for MultiLingual Model on the Multilingual testset')\n",
    "\n",
    "b, t = plt.ylim() # discover the values for bottom and top\n",
    "b += 0.5 # Add 0.5 to the bottom\n",
    "t -= 0.5 # Subtract 0.5 from the top\n",
    "plt.ylim(b, t) # update the ylim(bottom, top) values\n",
    "plt.savefig(\"confusion_multilingualmodel_multilingual_dataset.png\", bbox_inches='tight')\n",
    "plt.show() # ta-da!\n",
    "\n",
    "# Show the result\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilingual_multilingual_y_true = np.array(multilingual_multilingual_y_true)\n",
    "multilingual_multilingual_y_pred = np.array(multilingual_multilingual_y_pred)\n",
    "\n",
    "multilingual_multilingual_mae, multilingual_multilingual_stdev, multilingual_multilingual_relative_mae,multilingual_multilingual_rel_error = stats_calc(multilingual_multilingual_y_true, multilingual_multilingual_y_pred)\n",
    "\n",
    "print(\"MAE: {}\".format(multilingual_multilingual_mae))\n",
    "print(\"MAE St.Dev.: {}\".format(multilingual_multilingual_stdev))\n",
    "print(\"Relative MAE: {}\".format(multilingual_multilingual_relative_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Distribution of relative errors for the Baseline model on the Multilingual Testset\")\n",
    "plot_data_dist(baseline_multilingual_rel_error)\n",
    "print(\"Distribution of relative errors for the Multilingual model on the Multilingual Testset\")\n",
    "\n",
    "plot_data_dist(multilingual_multilingual_rel_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilingual_tval,multilingual_pval = ttest(baseline_multilingual_rel_error, multilingual_multilingual_rel_error)\n",
    "print(f\"The p val : {multilingual_pval} and t val : {multilingual_tval} for one sided (paired) t-test on the Multilingual dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unseen Data\n",
    "\n",
    "In this section the performance of the baseline and multilingual model will be evaluated on the Spanish and Polish datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/vol/tensusers3/camghane/ASR/MLS/baseline_predictions_experiment2_spanishdataset.json') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_spanish_y_true = data['y_true']\n",
    "baseline_spanish_y_pred = data['y_pred']\n",
    "\n",
    "cm_train = confusion_matrix(baseline_spanish_y_true, baseline_spanish_y_pred, labels=range(11))\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(1,1, figsize=(5,5))\n",
    "\n",
    "\n",
    "\n",
    "# Plot confusion matrix for training data\n",
    "sns.heatmap(cm_train, annot=True, fmt='g', ax=ax, cmap=\"Blues\")\n",
    "\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix for Baseline Model on the Spanish testset')\n",
    "\n",
    "b, t = plt.ylim() # discover the values for bottom and top\n",
    "b += 0.5 # Add 0.5 to the bottom\n",
    "t -= 0.5 # Subtract 0.5 from the top\n",
    "plt.ylim(b, t) # update the ylim(bottom, top) values\n",
    "plt.savefig(\"confusion_multilingualmodel_multilingual_dataset.png\", bbox_inches='tight')\n",
    "plt.show() # ta-da!\n",
    "\n",
    "# Show the result\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_spanish_y_true = np.array(baseline_spanish_y_true)\n",
    "baseline_spanish_y_pred = np.array(baseline_spanish_y_pred)\n",
    "\n",
    "baseline_spanish_mae, baseline_spanish_stdev, baseline_spanish_relative_mae, baseline_spanish_rel_error = stats_calc(baseline_spanish_y_true, baseline_spanish_y_pred)\n",
    "\n",
    "print(\"MAE: {}\".format(baseline_spanish_mae))\n",
    "print(\"MAE St.Dev.: {}\".format(baseline_spanish_stdev))\n",
    "print(\"Relative MAE: {}\".format(baseline_spanish_relative_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multilingual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/vol/tensusers3/camghane/ASR/MLS/multilingual_predictions_experiment2_spanishdataset.json') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilingual_spanish_y_true = data['y_true']\n",
    "multilingual_spanish_y_pred = data['y_pred']\n",
    "\n",
    "cm_train = confusion_matrix(multilingual_spanish_y_true, multilingual_spanish_y_pred, labels=range(11))\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(1,1, figsize=(5,5))\n",
    "\n",
    "\n",
    "\n",
    "# Plot confusion matrix for training data\n",
    "sns.heatmap(cm_train, annot=True, fmt='g', ax=ax, cmap=\"Blues\")\n",
    "\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix for MultiLingual Model on the Spanish testset')\n",
    "\n",
    "b, t = plt.ylim() # discover the values for bottom and top\n",
    "b += 0.5 # Add 0.5 to the bottom\n",
    "t -= 0.5 # Subtract 0.5 from the top\n",
    "plt.ylim(b, t) # update the ylim(bottom, top) values\n",
    "plt.savefig(\"confusion_multilingualmodel_multilingual_dataset.png\", bbox_inches='tight')\n",
    "plt.show() # ta-da!\n",
    "\n",
    "# Show the result\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilingual_spanish_y_true = np.array(multilingual_spanish_y_true)\n",
    "multilingual_spanish_y_pred = np.array(multilingual_spanish_y_pred)\n",
    "\n",
    "multilingual_spanish_mae, multilingual_spanish_stdev, multilingual_spanish_relative_mae, multilingual_spanish_rel_error = stats_calc(multilingual_spanish_y_true, multilingual_spanish_y_pred)\n",
    "\n",
    "print(\"MAE: {}\".format(multilingual_spanish_mae))\n",
    "print(\"MAE St.Dev.: {}\".format(multilingual_spanish_stdev))\n",
    "print(\"Relative MAE: {}\".format(multilingual_spanish_relative_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## polish dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/vol/tensusers3/camghane/ASR/MLS/baseline_predictions_experiment2_polishdataset.json') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_polish_y_true = data['y_true']\n",
    "baseline_polish_y_pred = data['y_pred']\n",
    "\n",
    "cm_train = confusion_matrix(baseline_polish_y_true, baseline_polish_y_pred, labels=range(11))\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(1,1, figsize=(5,5))\n",
    "\n",
    "\n",
    "\n",
    "# Plot confusion matrix for training data\n",
    "sns.heatmap(cm_train, annot=True, fmt='g', ax=ax, cmap=\"Blues\")\n",
    "\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix for Baseline Model on the Polish testset')\n",
    "\n",
    "b, t = plt.ylim() # discover the values for bottom and top\n",
    "b += 0.5 # Add 0.5 to the bottom\n",
    "t -= 0.5 # Subtract 0.5 from the top\n",
    "plt.ylim(b, t) # update the ylim(bottom, top) values\n",
    "plt.savefig(\"confusion_multilingualmodel_multilingual_dataset.png\", bbox_inches='tight')\n",
    "plt.show() # ta-da!\n",
    "\n",
    "# Show the result\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_polish_y_true = np.array(baseline_polish_y_true)\n",
    "baseline_polish_y_pred = np.array(baseline_polish_y_pred)\n",
    "\n",
    "baseline_polish_mae, baseline_polish_stdev, baseline_polish_relative_mae, baseline_polish_rel_error = stats_calc(baseline_polish_y_true, baseline_polish_y_pred)\n",
    "\n",
    "print(\"MAE: {}\".format(baseline_polish_mae))\n",
    "print(\"MAE St.Dev.: {}\".format(baseline_polish_stdev))\n",
    "print(\"Relative MAE: {}\".format(baseline_polish_relative_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multilingual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/vol/tensusers3/camghane/ASR/MLS/multilingual_predictions_experiment2_polishdataset.json') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilingual_polish_y_true = data['y_true']\n",
    "multilingual_polish_y_pred = data['y_pred']\n",
    "\n",
    "cm_train = confusion_matrix(multilingual_polish_y_true, multilingual_polish_y_pred, labels=range(11))\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(1,1, figsize=(5,5))\n",
    "\n",
    "\n",
    "\n",
    "# Plot confusion matrix for training data\n",
    "sns.heatmap(cm_train, annot=True, fmt='g', ax=ax, cmap=\"Blues\")\n",
    "\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix for MultiLingual Model on the Polish testset')\n",
    "\n",
    "b, t = plt.ylim() # discover the values for bottom and top\n",
    "b += 0.5 # Add 0.5 to the bottom\n",
    "t -= 0.5 # Subtract 0.5 from the top\n",
    "plt.ylim(b, t) # update the ylim(bottom, top) values\n",
    "plt.savefig(\"confusion_multilingualmodel_multilingual_dataset.png\", bbox_inches='tight')\n",
    "plt.show() # ta-da!\n",
    "\n",
    "# Show the result\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilingual_polish_y_true = np.array(multilingual_polish_y_true)\n",
    "multilingual_polish_y_pred = np.array(multilingual_polish_y_pred)\n",
    "\n",
    "multilingual_polish_mae, multilingual_polish_stdev, multilingual_polish_relative_mae, multilingual_polish_rel_error = stats_calc(multilingual_polish_y_true, multilingual_polish_y_pred)\n",
    "\n",
    "print(\"MAE: {}\".format(multilingual_polish_mae))\n",
    "print(\"MAE St.Dev.: {}\".format(multilingual_polish_stdev))\n",
    "print(\"Relative MAE: {}\".format(multilingual_polish_relative_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Distribution of relative errors for the Baseline model on the Spanish Testset\")\n",
    "plot_data_dist(baseline_spanish_rel_error)\n",
    "print(\"Distribution of relative errors for the Multilingual model on the Spanish Testset\")\n",
    "\n",
    "plot_data_dist(multilingual_spanish_rel_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_tval, spanish_pval = ttest(baseline_spanish_rel_error, multilingual_spanish_rel_error)\n",
    "print(f\"The p val : {spanish_pval} and t val : {spanish_tval} for one sided (paired) t-test on the Spanish dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Distribution of relative errors for the Baseline model on the Polish Testset\")\n",
    "plot_data_dist(baseline_polish_rel_error)\n",
    "print(\"Distribution of relative errors for the Multilingual model on the Polish Testset\")\n",
    "plot_data_dist(multilingual_polish_rel_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polish_tval, polish_pval = ttest(baseline_polish_rel_error, multilingual_polish_rel_error)\n",
    "print(f\"The p val : {polish_pval} and t val : {polish_tval} for one sided (paired) t-test on the Polish dataset\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
