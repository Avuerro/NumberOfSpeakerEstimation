{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A deeper dive into the model\n",
    "\n",
    "This notebook contains the code for creating the Saliency maps for each speaker condition,e.g. number of speakers in a sample. The saliency maps visualize which parts of the input are used by the model for each of the speaker conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from model import crnn \n",
    "from src import data\n",
    "from src import error_function\n",
    "from src.data import DataSet\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob \n",
    "import datetime\n",
    "import json\n",
    "import pdb\n",
    "from model import crnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVED_MODEL_DIR = '/vol/tensusers3/camghane/ASR/MLS/mls_experiment1_weights/MLS_exp1_model-best.h5'\n",
    "# SAVED_MODEL_DIR = 'pretrained_models/model-best-baseline.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(SAVED_MODEL_DIR, custom_objects={\n",
    "    'class_mae': error_function.class_mae\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/vol/tensusers3/camghane/ASR/LibriSpeech_test_clean/data/test-clean/merged/train/*/*.wav'\n",
    "BATCH_SIZE = 32\n",
    "### loading the data\n",
    "filenames = glob.glob(DATA_DIR)\n",
    "filenames_alt = {str(k):[] for k in range(0,11) }\n",
    "for filename in filenames:\n",
    "    filenames_alt[filename.split('/')[-2]].append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for nr_of_speakers, files_list in filenames_alt.items():\n",
    "    test_dataset = DataSet(files_list, scale_data = True).get_data()\n",
    "\n",
    "    audio_data = None\n",
    "    labels_data = None\n",
    "    for a, l in test_dataset.as_numpy_iterator():\n",
    "        labels_data = l\n",
    "        audio_data = a\n",
    "\n",
    "    saliency_map = np.zeros((500,201))\n",
    "    for i in range(len(audio_data)):\n",
    "        with tf.GradientTape() as tape:\n",
    "            audio = tf.Variable(audio_data)\n",
    "            tape.watch(audio)\n",
    "            pred = model(audio, training=False)\n",
    "            predictions_converted = [int(np.argmax(x)) for x in pred.numpy()]\n",
    "            loss = pred[i][predictions_converted[i]]\n",
    "\n",
    "        grads = tape.gradient(loss, audio)\n",
    "        df_grads = tf.math.abs(grads[i])\n",
    "        dgrad_max_ = df_grads\n",
    "        arr_min, arr_max  = np.min(dgrad_max_), np.max(dgrad_max_)\n",
    "        grad_eval = (dgrad_max_ - arr_min) / (arr_max - arr_min + 1e-18)\n",
    "        nr_of_speakers = np.argmax(labels_data[i])\n",
    "        saliency_map += tf.reshape(grad_eval, (500,201)).numpy()\n",
    "        \n",
    "    plt.imshow(saliency_map.T, vmin=0,vmax=1)\n",
    "    plt.colorbar()\n",
    "    plt.title(f'Saliency map for {nr_of_speakers} speakers')\n",
    "    plt.ylim([0,200])\n",
    "    plt.xlim([0,500])\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.savefig(f'english_Multilingual_model_Saliency_{nr_of_speakers}_speakers.png', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
