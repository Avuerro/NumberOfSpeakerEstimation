{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# import tensorflow_io as tfio\n",
    "# from tensorflow import keras\n",
    "from tensorflow.keras import Sequential,layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "# import keras\n",
    "from keras import backend as K\n",
    "from src import data\n",
    "from src import error_function\n",
    "from src import util\n",
    "from src.data import DataSet\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import IPython.display as ipd\n",
    "import os \n",
    "import glob \n",
    "import pdb\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_object = DataSet(\"../data/merged_outputtrain/*/*.wav\", val_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = dataset_object.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = []\n",
    "batch_label = []\n",
    "counter = 0\n",
    "for audio,label in train_dataset.as_numpy_iterator():\n",
    "    counter += 1\n",
    "    if(counter == 10):\n",
    "        batch_data = audio\n",
    "        batch_label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 6, 9, 1, 5, 3, 4, 8, 0, 8, 8, 2, 4, 8, 5, 1, 0, 2, 5, 6, 3,\n",
       "       9, 9, 6, 8, 3, 9, 3, 0, 9, 6], dtype=int16)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_label(filename):\n",
    "    return filename.split(\"/\")[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # @tf.function\n",
    "# def parse_function(filename, label):\n",
    "# #     audio_sample, sample_rate = tf.audio.decode_wav(filename)    \n",
    "#     audio_binary = tf.io.read_file(filename)\n",
    "# #     audio_decoded = tf.contrib.ffmpeg.decode_audio(\n",
    "# #         audio_binary,\n",
    "# #         file_format=\"wav\",\n",
    "# #         samples_per_second=16000,\n",
    "# #         channel_count=1\n",
    "# #     )\n",
    "# #     audio_path = tf.keras.utils.get_file('test.wav', filename)\n",
    "# #     audio = tfio.audio.AudioIODataset(audio_path)\n",
    "#     audio,sr = tf.audio.decode_wav(audio_binary)\n",
    "# #     print(audio.shape)\n",
    "#     pdb.set_trace()\n",
    "#     return tf.cast(audio, tf.float32),label\n",
    "# #https://github.com/faroit/python_audio_loading_benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_function(filename):\n",
    "    filepath = bytes.decode(filename.numpy())\n",
    "    audio, sample_rate = sf.read(filepath)\n",
    "    label = obtain_label(filepath)\n",
    "    return tf.cast(audio, tf.float32),label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_function_wrapper(filename):\n",
    "    return tf.py_function(func=parse_function, inp=[filename], Tout=(tf.float32, tf.string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator():\n",
    "    filenames = glob.glob('../data/merged_outputtrain/*/*')\n",
    "    labels = list(map(obtain_label, filenames))\n",
    "    for filename,label in zip(filenames,labels):\n",
    "        yield filename,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_excerpt(file,label): #length can be changed..\n",
    "    excerpt_duration=1\n",
    "    excerpt_duration_frames = excerpt_duration * 16000\n",
    "    limit = 80000 - excerpt_duration_frames\n",
    "    start = np.random.randint(0,limit)\n",
    "    return tf.slice(tf.squeeze(file), [start], [excerpt_duration_frames-1]),label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stft(data,n_fft=400,hop_length=160,window=signal.windows.hann):\n",
    "    #return np.abs(librosa.stft(data, n_fft=n_fft,hop_length=hop_length,window=window)).T\n",
    "#frame_length = n_fft\n",
    "#frame_step = hop_length\n",
    "def stft_tf(audio_tensor, label):\n",
    "    data = audio_tensor.numpy()\n",
    "    stft = util.stft(data)\n",
    "    label = int(bytes.decode(label.numpy()))\n",
    "    return tf.cast(util.stft(data), tf.float32),tf.convert_to_tensor(label, dtype=tf.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft_wrapper(audiofile, label): \n",
    "    audio, label = tf.py_function(func=stft_tf, inp=[audiofile,label], Tout=(tf.float32,tf.int16) )\n",
    "    return audio, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(audiofile, label):\n",
    "    return tf.reshape(audiofile,shape=(1,100,201)), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = tf.io.gfile.glob(\"../data/merged_outputtrain/*/*.wav\")#glob.glob('../data/merged_outputtrain/*/*')\n",
    "labels = list( map(obtain_label, filenames) )\n",
    "X_train, X_val, y_train, y_val = train_test_split(filenames, labels,\n",
    "                                                  train_size=0.8, \n",
    "                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/merged_outputtrain/7/7_1186.wav', '../data/merged_outputtrain/2/2_341.wav', '../data/merged_outputtrain/5/5_1024.wav', '../data/merged_outputtrain/9/9_848.wav', '../data/merged_outputtrain/7/7_786.wav', '../data/merged_outputtrain/4/4_553.wav', '../data/merged_outputtrain/5/5_64.wav', '../data/merged_outputtrain/4/4_213.wav', '../data/merged_outputtrain/2/2_91.wav', '../data/merged_outputtrain/2/2_1291.wav']\n",
      "['7', '2', '5', '9', '7', '4', '5', '4', '2', '2']\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:10])\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/merged_outputtrain/3/3_682.wav', '../data/merged_outputtrain/1/1_40.wav', '../data/merged_outputtrain/4/4_1913.wav', '../data/merged_outputtrain/6/6_1505.wav', '../data/merged_outputtrain/3/3_312.wav', '../data/merged_outputtrain/9/9_1648.wav', '../data/merged_outputtrain/4/4_1253.wav', '../data/merged_outputtrain/9/9_438.wav', '../data/merged_outputtrain/1/1_370.wav', '../data/merged_outputtrain/1/1_1300.wav']\n",
      "['3', '1', '4', '6', '3', '9', '4', '9', '1', '1']\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:10])\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames = glob.glob('../data/merged_outputtrain/*/*')\n",
    "# labels = list( map(obtain_label, filenames) )\n",
    "# dataset = tf.data.Dataset.from_tensor_slices( (filenames,labels) )\n",
    "\n",
    "dataset= tf.data.Dataset.list_files(X_train)\n",
    "# dataset = tfio.audio.AudioIODataset( (filenames[0],labels[0]) ) causes kernel crash!!!\n",
    "# dataset = tfio.audio.AudioIOTensor( filenames[0], dtype=tf.float64)\n",
    "dataset = dataset.map(parse_function_wrapper, num_parallel_calls=4)\n",
    "dataset = dataset.map(select_random_excerpt, num_parallel_calls=4)\n",
    "dataset = dataset.map(stft_wrapper, num_parallel_calls=4)\n",
    "dataset = dataset.map(reshape, num_parallel_calls=4)\n",
    "dataset = dataset.batch(32)\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = []\n",
    "batch_label = []\n",
    "counter = 0\n",
    "for audio,label in dataset.as_numpy_iterator():\n",
    "    counter += 1\n",
    "    if(counter == 10):\n",
    "        batch_data = audio\n",
    "        batch_label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.keras.initializers.VarianceScaling(\n",
    "    scale=1.0, mode=\"fan_avg\", distribution=\"uniform\", seed=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        layers.ZeroPadding2D(padding=((0,0),(0,0)), batch_input_shape=(None, 1,500,201),name=\"zero1\",data_format=\"channels_last\"),\n",
    "        layers.Conv2D(64,kernel_size=(3,3),strides=(1,1),name=\"conv1\",activation=\"relu\",kernel_initializer=initializer,data_format=\"channels_first\"),\n",
    "        layers.Conv2D(32,kernel_size=(3,3),strides=(1,1),name=\"conv2\",activation=\"relu\",kernel_initializer=initializer,data_format=\"channels_first\"),\n",
    "        layers.MaxPool2D(pool_size=(3,3),strides=(3,3),trainable=True,name=\"pool1\",data_format=\"channels_first\"),\n",
    "        layers.Conv2D(128,kernel_size=(3,3),strides=(1,1),name=\"conv3\",activation=\"relu\",kernel_initializer=initializer,data_format=\"channels_first\"),\n",
    "        layers.Conv2D(64,kernel_size=(3,3),strides=(1,1),name=\"conv4\",activation=\"relu\",kernel_initializer=initializer, data_format=\"channels_first\"),\n",
    "        layers.MaxPool2D(pool_size=(3,3),strides=(3,3),trainable=True,name=\"pool2\",data_format=\"channels_first\"),\n",
    "        layers.Dropout(0.5, trainable=True, name=\"dropout_1\"),\n",
    "        layers.Permute((2,1,3),trainable=True,name=\"permute_1\"),\n",
    "        layers.Reshape((53,-1),trainable=True,name=\"reshape_1\"),\n",
    "        layers.LSTM(40, return_sequences=True,kernel_initializer=initializer,name=\"lstm_1\",batch_input_shape=(None, None, 1280)),\n",
    "        layers.MaxPool1D(pool_size=(2,),strides=(2,),trainable=True, name=\"maxpooling1d_1\", data_format=\"channels_last\"),\n",
    "        layers.Flatten(name=\"flatten1\",trainable=True),\n",
    "        layers.Dense(11,activation=\"linear\",kernel_initializer=initializer,trainable=True,name=\"dense_1\", batch_input_shape=(None, 1040)),\n",
    "        layers.Softmax(trainable=True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer,\n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": " Default MaxPoolingOp only supports NHWC on device type CPU\n\t [[node sequential/pool1/MaxPool (defined at <ipython-input-50-d28793719248>:1) ]] [Op:__inference_train_function_74811]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-d28793719248>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py37asr_alt/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37asr_alt/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37asr_alt/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37asr_alt/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37asr_alt/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37asr_alt/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/py37asr_alt/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Default MaxPoolingOp only supports NHWC on device type CPU\n\t [[node sequential/pool1/MaxPool (defined at <ipython-input-50-d28793719248>:1) ]] [Op:__inference_train_function_74811]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "model.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
