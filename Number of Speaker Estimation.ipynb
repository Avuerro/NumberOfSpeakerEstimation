{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as scipy\n",
    "import os\n",
    "import sys\n",
    "from scipy.io import wavfile\n",
    "import soundfile as sf\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.insert(0, './src/')\n",
    "from src import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#util.flacs_to_wavs()\n",
    "util.split_audio_in_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading FLAC, remove silence, write as WAV\n",
    "\n",
    "For this, we downloaded the [LibriSpeech Clean Speech Develoment Set](https://www.openslr.org/resources/12/dev-clean.tar.gz), and unpacked it in the \"/data\" folde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data, samplerate = sf.read(\"./data/LibriSpeech/dev-clean/84/121123/84-121123-0000.flac\")\n",
    "print(len(data))\n",
    "data = data[data != 0.]\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.min())\n",
    "print(data.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavfile.write(\"./samples/84-121123-0000.wav\", samplerate, data)\n",
    "ipd.Audio(\"./samples/84-121123-0000.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Audio Files of Certain Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First load in an audio file, check how long it is and its samplerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1, samplerate = sf.read(\"./data/LibriSpeech/dev-clean/84/121123/84-121123-0002.flac\")\n",
    "wavfile.write(\"./samples/84-121123-0002.wav\", samplerate, sample1)\n",
    "print(len(sample1))\n",
    "print(samplerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An array length of `219040` and a sample rate of `16000` means that the length of this audio file is $\\frac{219040}{16000} \\approx 13$ seconds. Let's load in the `.wav` version of this file, to see if it is indeed roughly 13 seconds long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ipd.Audio(\"./samples/84-121123-0002.wav\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we were correct. So, in order to make this sample 5 seconds long instead of 13, we have to save the first $5 \\cdot 16000 = 80000$ elements in our sample array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1, samplerate = sf.read(\"./data/LibriSpeech/dev-clean/84/121123/84-121123-0002.flac\")\n",
    "shorter_sample1 = sample1[0:5*samplerate]\n",
    "wavfile.write(\"./samples/84-121123-0002-5secs.wav\", samplerate, shorter_sample1)\n",
    "ipd.Audio(\"./samples/84-121123-0002-5secs.wav\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we have indeed succesfully cut the audio sample down to 5 seconds!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min-Max Normalization for Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1, samplerate = sf.read(\"./data/LibriSpeech/dev-clean/84/121123/84-121123-0002.flac\")\n",
    "wavfile.write(\"./samples/84-121123-0002.wav\", samplerate, sample1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample1.max())\n",
    "print(sample1.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(\"./samples/84-121123-0002.wav\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = -1\n",
    "b = 1\n",
    "\n",
    "max1 = sample1.max()\n",
    "min1 = sample1.min()\n",
    "\n",
    "normalized_sample1 = a + ((sample1 - min1) * (b - a))/(max1 - min1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(normalized_sample1.max())\n",
    "print(normalized_sample1.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavfile.write(\"./samples/84-121123-0002_minmax.wav\", samplerate, normalized_sample1)\n",
    "ipd.Audio(\"./samples/84-121123-0002_minmax.wav\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = -0.1\n",
    "b = 0.1\n",
    "\n",
    "max1 = sample1.max()\n",
    "min1 = sample1.min()\n",
    "\n",
    "normalized_sample1 = a + ((sample1 - min1) * (b - a))/(max1 - min1)\n",
    "wavfile.write(\"./samples/84-121123-0002_very_quiet.wav\", samplerate, normalized_sample1)\n",
    "ipd.Audio(\"./samples/84-121123-0002_very_quiet.wav\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Two Audio Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading in a `.flac` file, we rewrite it as a `.wav`, and we can then listen to this file via the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample1, samplerate = sf.read(\"./data/LibriSpeech/dev-clean/84/121123/84-121123-0002.flac\")\n",
    "wavfile.write(\"./samples/84-121123-0002.wav\", samplerate, sample1)\n",
    "ipd.Audio(\"./samples/84-121123-0002.wav\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be some silent moments in the audio file, which we can filter out by running the next cell. Note how the lengths of the sample change. Although I am not sure if this is really needed in the end product, it is nice to show how it is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(sample1))\n",
    "#sample1 = sample1[sample1 != 0.]\n",
    "print(len(sample1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(219040/16000)\n",
    "print(218703/16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets save this shortened sample, and listen to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavfile.write(\"./samples/84-121123-0002-shortened.wav\", samplerate, sample1)\n",
    "ipd.Audio(\"./samples/84-121123-0002-shortened.wav\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this for a second audio fragment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2, samplerate = sf.read(\"./data/LibriSpeech/dev-clean/174/50561/174-50561-0006.flac\")\n",
    "wavfile.write(\"./samples/174-50561-0006.wav\", samplerate, sample2)\n",
    "ipd.Audio(\"./samples/174-50561-0006.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sample2))\n",
    "sample2 = sample2[sample2 != 0.]\n",
    "print(len(sample2))\n",
    "wavfile.write(\"./samples/174-50561-0006-shortened.wav\", samplerate, sample2)\n",
    "ipd.Audio(\"./samples/174-50561-0006-shortened.wav\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that the audio files have the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sample1) > len(sample2):\n",
    "    sample1 = sample1[0:len(sample2)]\n",
    "else:\n",
    "    sample2 = sample2[0:len(sample1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Audio processing magic](https://stackoverflow.com/questions/4039158/mixing-two-audio-files-together-with-python): add the two signals and divide them by two, and lets listen to the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample = (sample1 + sample2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavfile.write(\"./samples/test_merging.wav\", samplerate, new_sample)\n",
    "ipd.Audio(\"./samples/test_merging.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Lange termijn:\n",
    " - Netwerk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute STFT\n",
    "\n",
    "In the countnet paper, STFT's are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.abs(librosa.stft(sample1, n_fft=400, hop_length=160)).T\n",
    "X2 = np.abs(librosa.stft(sample2, n_fft=400, hop_length=160)).T\n",
    "XM = np.abs(librosa.stft(new_sample, n_fft=400, hop_length=160)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(1,3, figsize=(10,10))\n",
    "f.patch.set_facecolor('white')\n",
    "axarr[0].imshow(X1)\n",
    "axarr[0].set_title('Sample 1')\n",
    "axarr[1].imshow(X2)\n",
    "axarr[1].set_title('Sample 2')\n",
    "axarr[2].imshow(XM)\n",
    "axarr[2].set_title('Merged Sample')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading all filepaths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "splits_dir = './data/wav_splits/'\n",
    "speakers = os.listdir(splits_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "files_per_speaker = []\n",
    "nr_of_files = 0\n",
    "for speaker in speakers:\n",
    "    speaker_files = []\n",
    "    for subdir, dirs, files in os.walk(splits_dir+\"/{}\".format(speaker)):\n",
    "        for f in files:\n",
    "            nr_of_files +=1\n",
    "            speaker_files.append(splits_dir+f)\n",
    "    files_per_speaker.append(speaker_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(files_per_speaker)\n",
    "print(\"In total, there are {} audio samples\".format(nr_of_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "splits_dir = './data/train100/train-clean-100'\n",
    "speakers = os.listdir(splits_dir)\n",
    "\n",
    "files_per_speaker = []\n",
    "nr_of_files = 0\n",
    "for speaker in speakers:\n",
    "    speaker_files = []\n",
    "    #print(len(files_per_speaker))\n",
    "    \n",
    "        \n",
    "    for subdir, dirs, files in os.walk(splits_dir+\"/{}\".format(speaker)):\n",
    "        for f in files:\n",
    "            if f.endswith('.wav'):\n",
    "                nr_of_files +=1\n",
    "                speaker_files.append(splits_dir+f)\n",
    "    if len(speaker_files) > 0:\n",
    "        files_per_speaker.append(speaker_files)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59959\n"
     ]
    }
   ],
   "source": [
    "print(nr_of_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12051 unique datapoints created\n"
     ]
    }
   ],
   "source": [
    "files_per_speaker = np.array(files_per_speaker)\n",
    "amount_of_datapoints = 0\n",
    "combinations = []\n",
    "\n",
    "\n",
    "i = 1\n",
    "# for i in range(1, val_amount+1):\n",
    "while(files_per_speaker.shape[0] > 0):\n",
    "    amount_of_speakers = i % 11\n",
    "    \n",
    "    # Check how many speakers are still in the dataset\n",
    "    number_of_rows = files_per_speaker.shape[0]\n",
    "\n",
    "    # When the amount of speakers is larger than nr of rows, decrease amount of speakers until we can sample again\n",
    "    while( amount_of_speakers > number_of_rows):\n",
    "        amount_of_speakers -= 1\n",
    "        \n",
    "    random_speaker_ids = np.random.choice(number_of_rows, size=amount_of_speakers, replace=False)\n",
    "    #print(random_speaker_ids)\n",
    "    ids_to_remove = []\n",
    "    \n",
    "    files_to_merge = []\n",
    "    for speaker_id in random_speaker_ids:\n",
    "        # Load all files for this speaker:\n",
    "        speaker_files = files_per_speaker[speaker_id]\n",
    "        # For each random speaker, pick one random file:\n",
    "        random_file = np.random.choice(speaker_files)\n",
    "        \n",
    "        files_to_merge.append(random_file)\n",
    "        # Remove file from original set, to prevent duplicates among merged files\n",
    "        files_per_speaker[speaker_id] = np.delete(files_per_speaker[speaker_id], np.where(files_per_speaker[speaker_id] == random_file)[0])\n",
    "           \n",
    "        # If all files from a single speaker are used: remove the speakers, to prevent sampling from empty lists\n",
    "        if len(files_per_speaker[speaker_id]) == 0:\n",
    "            ids_to_remove.append(speaker_id)\n",
    "    \n",
    "    # data = np.zeros(18000)\n",
    "    ## For all files in files_to_merge:\n",
    "        # data += files\n",
    "    # data = data / len(files_to_merge)\n",
    "    \n",
    "    # Data opslaan naar een mapje, zodat we ook bijhouden hoeveel sprekers erin zitten\n",
    "    # E.g. opslaan als : \"{}_{}.wav\".format(amount_of_speaker, amount_of_datapoints)\n",
    "    #      of: voor iedere class een aparte map\n",
    "    # Mss een .txt uitschrijven met dezelfde naam als het audio bestand, met daarin random_speaker_ids\n",
    "    \n",
    "    files_per_speaker = np.delete(files_per_speaker, ids_to_remove)\n",
    "    # Increment counter for calculating amount of speakers\n",
    "    i += 1\n",
    "    amount_of_datapoints +=1\n",
    "\n",
    "print(\"{} unique datapoints created\".format(amount_of_datapoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
